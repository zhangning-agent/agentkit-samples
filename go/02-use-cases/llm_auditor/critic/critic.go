// Copyright (c) 2025 Beijing Volcano Engine Technology Co., Ltd. and/or its affiliates.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package critic

import (
	"fmt"
	"strings"

	veagent "github.com/volcengine/veadk-go/agent/llmagent"
	"github.com/volcengine/veadk-go/common"
	"github.com/volcengine/veadk-go/tool/builtin_tools/web_search"
	"github.com/volcengine/veadk-go/utils"
	"google.golang.org/adk/agent"
	"google.golang.org/adk/agent/llmagent"
	"google.golang.org/adk/model"
	"google.golang.org/adk/tool"
	"google.golang.org/genai"
)

const CriticPrompt = `
You are a professional investigative journalist, excelling at critical thinking and verifying information before printed to a highly-trustworthy publication.
In this task you are given a question-answer pair to be printed to the publication. The publication editor tasked you to double-check the answer text.

# Your task

Your task involves three key steps: First, identifying all CLAIMS presented in the answer. Second, determining the reliability of each CLAIM. And lastly, provide an overall assessment.

## Step 1: Identify the CLAIMS

Carefully read the provided answer text. Extract every distinct CLAIM made within the answer. A CLAIM can be a statement of fact about the world or a logical argument presented to support a point.

## Step 2: Verify each CLAIM

For each CLAIM you identified in Step 1, perform the following:

* Consider the Context: Take into account the original question and any other CLAIMS already identified within the answer.
* Consult External Sources: Use your general knowledge and/or search the web to find evidence that supports or contradicts the CLAIM. Aim to consult reliable and authoritative sources.
* Determine the VERDICT: Based on your evaluation, assign one of the following verdicts to the CLAIM:
    * Accurate: The information presented in the CLAIM is correct, complete, and consistent with the provided context and reliable sources.
    * Inaccurate: The information presented in the CLAIM contains errors, omissions, or inconsistencies when compared to the provided context and reliable sources.
    * Disputed: Reliable and authoritative sources offer conflicting information regarding the CLAIM, indicating a lack of definitive agreement on the objective information.
    * Unsupported: Despite your search efforts, no reliable source can be found to substantiate the information presented in the CLAIM.
    * Not Applicable: The CLAIM expresses a subjective opinion, personal belief, or pertains to fictional content that does not require external verification.
* Provide a JUSTIFICATION: For each verdict, clearly explain the reasoning behind your assessment. Reference the sources you consulted or explain why the verdict "Not Applicable" was chosen.

## Step 3: Provide an overall assessment

After you have evaluated each individual CLAIM, provide an OVERALL VERDICT for the entire answer text, and an OVERALL JUSTIFICATION for your overall verdict. Explain how the evaluation of the individual CLAIMS led you to this overall assessment and whether the answer as a whole successfully addresses the original question.

# Tips

Your work is iterative. At each step you should pick one or more claims from the text and verify them. Then, continue to the next claim or claims. You may rely on previous claims to verify the current claim.

There are various actions you can take to help you with the verification:
  * You may use your own knowledge to verify pieces of information in the text, indicating "Based on my knowledge...". However, non-trivial factual claims should be verified with other sources too, like Search. Highly-plausible or subjective claims can be verified with just your own knowledge.
  * You may spot the information that doesn't require fact-checking and mark it as "Not Applicable".
  * You may search the web to find information that supports or contradicts the claim.
  * You may conduct multiple searches per claim if acquired evidence was insufficient.
  * In your reasoning please refer to the evidence you have collected so far via their squared brackets indices.
  * You may check the context to verify if the claim is consistent with the context. Read the context carefully to idenfity specific user instructions that the text should follow, facts that the text should be faithful to, etc.
  * You should draw your final conclusion on the entire text after you acquired all the information you needed.

# Output format

The last block of your output should be a Markdown-formatted list, summarizing your verification result. For each CLAIM you verified, you should output the claim (as a standalone statement), the corresponding part in the answer text, the verdict, and the justification.

Here is the question and answer you are going to double check:
`

func New() (agent.Agent, error) {
	webSearch, err := web_search.NewWebSearchTool(&web_search.Config{})
	if err != nil {
		return nil, fmt.Errorf("NewWebSearchTool error: %w", err)
	}

	return veagent.New(&veagent.Config{
		Config: llmagent.Config{
			Name:        "critic_agent",
			Instruction: CriticPrompt,
			Tools:       []tool.Tool{webSearch},
			AfterModelCallbacks: []llmagent.AfterModelCallback{
				renderReference,
			},
		},
		ModelName: utils.GetEnvWithDefault(common.MODEL_AGENT_NAME, "deepseek-v3-2-251201"),
	})
}

func renderReference(
	ctx agent.CallbackContext,
	llmResponse *model.LLMResponse,
	respErr error,
) (*model.LLMResponse, error) {
	if llmResponse.Content == nil ||
		llmResponse.Content.Parts == nil ||
		llmResponse.GroundingMetadata == nil {
		return llmResponse, nil
	}
	var references []string
	for _, chunk := range llmResponse.GroundingMetadata.GroundingChunks {
		var title, uri, text string
		if chunk.RetrievedContext != nil {
			title = chunk.RetrievedContext.Title
			uri = chunk.RetrievedContext.URI
			text = chunk.RetrievedContext.Text
		} else if chunk.Web != nil {
			title = chunk.Web.Title
			uri = chunk.Web.URI
		}
		var parts []string
		if title != "" {
			parts = append(parts, title)
		}
		if text != "" {
			parts = append(parts, text)
		}
		if uri != "" && len(parts) > 0 {
			parts[0] = fmt.Sprintf("[%s](%s)", parts[0], uri)
		}
		if len(parts) > 0 {
			references = append(references, "* "+strings.Join(parts, ": ")+"\n")
		}
	}
	if len(references) > 0 {
		referenceText := "\n\nReference:\n\n" + strings.Join(references, "")
		llmResponse.Content.Parts = append(
			llmResponse.Content.Parts,
			&genai.Part{Text: referenceText},
		)
	}

	allTextBased := true
	var allText []string
	for _, p := range llmResponse.Content.Parts {
		// Check if the part contains non-text data.
		if p.FunctionCall != nil || p.InlineData != nil || p.FunctionResponse != nil {
			allTextBased = false
			break
		}
		allText = append(allText, p.Text)
	}

	// Only consolidate if all parts were text-based
	if allTextBased {
		llmResponse.Content.Parts[0].Text = strings.Join(allText, "\n")
		llmResponse.Content.Parts = llmResponse.Content.Parts[:1]
	}

	return llmResponse, nil
}
